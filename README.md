# MHATB

## IJCV 2023 | Benchmarking the Complementary-View Multi-human Association and Tracking

<div align= justify>

## The first dataset including the complementary top- and horizontal-view videos taken by multiple moving cameras. 

[2024.10] We have uploaded some metadata generated from our method to Baidu Netdisk.

Data Link: https://pan.baidu.com/s/1m9mXxDALsV-Tm5UI1M-0Xw 
Passwordï¼š MHAT

[2023.12] We have uploaded the dataset with annotations at Baidu Netdisk.

Dataset Link: https://pan.baidu.com/s/1tw8voHsDp-Fgv0mWim7kgA
Password: MHAT 

## Introduction

Using multiple moving cameras with different and time-varying views can significantly expand the capability of multiple human tracking in larger areas and with various perspectives. In particular, the use of moving cameras of complementary top and horizontal views can facilitate multi-human detection and tracking from both global and local perspectives. As a new challenging problem that has drawn more and more attention in recent years, one main issue is the lack of a comprehensive dataset for credible performance evaluation. In this paper, we present such a new dataset consisting of videos synchronously recorded by drone and wearable cameras, with high-quality annotations of the covered subjects and their cross-frame and cross-view associations. We also propose a pertinent baseline algorithm for multi-view multiple human tracking and evaluate it on this new dataset against the annotated ground truths. Experimental results verify the usefulness of the new dataset and the effectiveness of the proposed baseline algorithm.

```
@article{han2023benchmarking,
  title={Benchmarking the Complementary-View Multi-human Association and Tracking},
  author={Ruize Han, Wei Feng, Feifan Wang, Zekun Qian, Haomin Yan, Song Wang},
  journal={International Journal of Computer Vision},
  year={2023},
  organization={Springer}
}
```
